# ==========================================
# ‚ö° N8N WORKFLOW AI CONFIGURATION
# ==========================================
# This file contains settings for all supported AI providers.
# To activate a configuration, remove the '#' from the beginning of the line.
#
# NOTE: Sensitive API keys should not be shared.

# ==========================================
# ü§ñ CHATGPT (OpenAI)
# ==========================================

# --- Authentication ---
# OpenAI API Key (Starts with sk-...)
OPENAI_API_KEY=INSERT_YOUR_KEY_HERE

# --- Main Models (High Intelligence) ---
# GPT-4o: Primary model, multimodal, fast and intelligent. (Recommended)
# OPENAI_MODEL=gpt-4o

# GPT-4 Turbo: Previous version of GPT-4, large context window.
# OPENAI_MODEL=gpt-4-turbo

# --- Reasoning Models (Reasoning) ---
# o1-preview: Model focused on complex reasoning and STEM.
# OPENAI_MODEL=o1-preview

# o1-mini: Smaller and faster version of the reasoning model.
# OPENAI_MODEL=o1-mini

# --- Lightweight Models (Cost Effective) ---
# GPT-4o-mini: Replacement for GPT-3.5, very fast and cheap.
OPENAI_MODEL=gpt-4o-mini

# --- Optional Parameters ---
# OPENAI_TEMPERATURE=0.7
# OPENAI_MAX_TOKENS=4096


# ==========================================
# üê≥ DEEPSEEK
# ==========================================

# --- Authentication ---
# DeepSeek API Key
DEEPSEEK_API_KEY=INSERT_YOUR_KEY_HERE

# Base URL (Usually does not need to be changed)
DEEPSEEK_BASE_URL=https://api.deepseek.com

# --- Models ---
# DeepSeek Chat (V3): Main model for chat and general use. (Recommended)
DEEPSEEK_MODEL=deepseek-chat

# DeepSeek Coder: Specialized in code generation and analysis.
# DEEPSEEK_MODEL=deepseek-coder

# DeepSeek Reasoner (R1): Advanced reasoning model.
# DEEPSEEK_MODEL=deepseek-reasoner


# ==========================================
# üî∂ CLAUDE (Anthropic)
# ==========================================

# --- Authentication ---
# Anthropic API Key (Starts with sk-ant-...)
# ANTHROPIC_API_KEY=your_key_here

# --- Current Models: Claude 3.5 (State of the Art) ---

# Claude 3.5 Sonnet: The current industry standard for coding and reasoning.
# Outperforms previous Opus models while being faster and cheaper. (Highly Recommended)
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Claude 3.5 Haiku: The fastest model.
# Intelligence similar to Claude 3 Opus but at a fraction of the cost/speed.
# ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# --- Legacy / Specialized Models (Claude 3) ---

# Claude 3 Opus: Previous flagship. Very "literary" and capable, but generally 
# slower and more expensive than 3.5 Sonnet. Good for nuanced creative writing.
# ANTHROPIC_MODEL=claude-3-opus-20240229

# Claude 3 Haiku: Previous fast generation. Use only if you need extreme cost savings.
# ANTHROPIC_MODEL=claude-3-haiku-20240307


# ==========================================
# üåå GROK (xAI)
# ==========================================

# --- Authentication ---
# xAI API Key
# XAI_API_KEY=your_key_here
# or
# GROK_API_KEY=your_key_here

# --- Models ---
# --- Grok 2 (Latest Stable - Recommended) ---

# Grok 2 (1212): The latest stable release. Significantly smarter, better 
# reasoning, and more consistent than the initial Beta.
# GROK_MODEL=grok-2-1212

# Grok 2 Vision (1212): The multimodal version of Grok 2.
# Use this if you need to analyze images or visual inputs.
# GROK_MODEL=grok-2-vision-1212

# --- Legacy / Beta Models ---

# Grok Beta: The previous generation. Kept for compatibility, but 
# generally less capable than Grok 2.
# GROK_MODEL=grok-beta


# ==========================================
# ‚ú® GEMINI (Google)
# ==========================================

# --- Authentication ---
# Paste your Google AI Studio key below (no quotes needed)
GOOGLE_API_KEY=INSERT_YOUR_KEY_HERE

# --- Gemini 2.0 (Next Gen - Experimental/Preview) ---
# Gemini 2.0 Flash: The newest generation. Multimodal, extremely fast, 
# and features improved reasoning capabilities. Currently the SOTA preview.
#GEMINI_MODEL=gemini-2.0-flash-exp

# --- Gemini 1.5 (Production / Stable) ---
# Gemini 1.5 Pro: The smartest model for complex reasoning, coding, and 
# deep analysis. Supports huge context windows (up to 2M tokens).
# GEMINI_MODEL=gemini-1.5-pro

# Gemini 1.5 Flash: The best balance between cost, speed, and intelligence.
# Recommended for most standard production applications.
GEMINI_MODEL=gemini-1.5-flash

# Gemini 1.5 Flash-8B: The "Mini" version. Lowest cost and lowest latency.
# Best for high-volume simple tasks (simple chatbots, summarization).
# GEMINI_MODEL=gemini-1.5-flash-8b
